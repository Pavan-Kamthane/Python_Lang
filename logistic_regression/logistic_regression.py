# -*- coding: utf-8 -*-
"""LAB4_logistic_regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T5Iw5fhbcq2sSoD_odJca-K-YHIeOeBF

# #Logistic Regression

 #Let’s make the Logistic Regression model, predicting whether a user will
 #purchase the product or not.

 #Imputing Libraries

#matplotlib. pyplot is a collection of functions that make matplotlib work like MATLAB
#pandas library use for manipulation and analysis of data
#numpy consit 0f multidimesional array objects
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""# Loading dataset – User_Data"""

dataset = pd.read_csv("Iris.csv")

"""Now, to predict whether a user will purchase the product or not,
#one needs to find out the relationship between Age and Estimated Salary.
#Here User ID and Gender are not important factors for finding out this.

# input
"""

x = dataset.iloc[:, [2,3,4]].values

x

"""only take column 2 and 3 as input

# output
"""

y = dataset.iloc[:, 5].values

y

"""only take column 4 as output"""

dataset.shape

"""sae explain the size of rows and columns """

dataset.head(150)

"""only take first 100 values

# spliting

now we split the data into two parts for training and testing 75% for training nad 25% for testing
"""

from sklearn.model_selection import train_test_split

xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.30, random_state =0)

"""#Now, it is very important to perform feature scaling here
#because Age and Estimated Salary values lie in different ranges.
#If we don’t scale the features
#then Estimated Salary feature will dominate Age feature
#when the model finds the nearest neighbor to a data point in data space.
#Here once see that Age and Estimated salary features values are sacled 39.# and now there in the -1 to 1.
#Hence, each feature will contribute equally in decision making
#i.e. finalizing the hypothesis.

# scaling
"""

from sklearn.preprocessing import StandardScaler
sc_x = StandardScaler()
xtrain = sc_x.fit_transform(xtrain)
xtest = sc_x.transform(xtest)

print (xtrain[0 : 50, :])

"""Finally, we are training our Logistic Regression model"""

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state = 0)
classifier.fit(xtrain, ytrain)

"""After training the model, it time to use it to do prediction on testing data"""

y_pred = classifier.predict(xtest)

y_pred

ytest

"""# performance testing and accuracy"""

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(ytest, y_pred)
print ("Confusion Matrix : \n", cm)

from sklearn.metrics import accuracy_score
print ("Accuracy : ", accuracy_score(ytest, y_pred))

"""# visualizing the performance of model"""

from matplotlib.colors import ListedColormap
X_set, y_set = xtest, ytest
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, 
                               stop = X_set[:, 0].max() + 1,step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1,
                               stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, classifier.predict(
              np.array([X1.ravel(),
              X2.ravel()]).T).
             reshape(X1.shape), alpha = 0.75, cmap = ListedColormap(('black', 'grey')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c = ListedColormap(('red', 'green'))(i), label = j)
plt.title('Classifier (Test set)')
plt.xlabel('Age')
plt.ylabel('Estimated Salary')
plt.legend()
plt.show()